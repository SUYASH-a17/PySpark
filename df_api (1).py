# -*- coding: utf-8 -*-
"""DF_API.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1972wBQlMVaN1fWSRSA_aJbwAP_zRUwdx
"""

import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("PySpark DF").getOrCreate()
import pandas as pd
import requests
from io import StringIO
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType, BooleanType

url = "https://data.cityofchicago.org/resource/ijzp-q8t2.csv"
response = requests.get(url)
csv_data = StringIO(response.text)
pandas_df = pd.read_csv(csv_data)
# Convert the Pandas DataFrame to a Spark DataFrame
df = spark.createDataFrame(pandas_df)
# Display the first 5 rows of the DataFrame (optional)
df.show(5)

df.printSchema()

df.columns

Labels = [
    ('ID', StringType()),
    ('case_number', StringType()),
    ('Date', StringType()),
    ('block', StringType()),
    ('iucr', StringType()),
    ('primary_type', StringType()),
    ('description', StringType()),
    ('location_description', StringType()),
    ('arrest', StringType()),
    ('domestic', BooleanType()),
    ('beat', StringType()),
    ('district', StringType()),
    ('ward', StringType()),
    ('community_area', StringType()),
    ('fbi_code', StringType()),
    ('x_coordinate', StringType()),
    ('y_coordinate', StringType()),
    ('year', IntegerType()),
    ('updated_on', StringType()),
    ('latitude', DoubleType()),
    ('longitude', DoubleType()),
    ('location', StringType())]

schema = StructType([StructField(x[0], x[1], True) for x in Labels])
schema

df1 = spark.createDataFrame(df.rdd, schema=schema) # Use createDataFrame with the existing DataFrame's RDD and the schema
df1.printSchema()

df1.show(5)

